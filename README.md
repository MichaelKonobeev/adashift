# Adashift

Reproducing of the (AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods)[https://openreview.net/forum?id=HkgTkhRcKQ]


## Experiments

## Results

**Synthetic Experiment**

![Synthetic](/img/regret_synth.png) ![Synthetic_optval](/img/opt_synth.png)


**Logistic Regression on MNIST**

![LR1](/img/mnist_LR_smooth_1000.png) ![LR2](/img/mnist_LR_1000.png)


## Dependencies

- Python 3.4+,
- NumPy 
- PyTorch 0.4+
- SciPy, Matplotlib
- A recent NVIDIA GPU

### References

On the Convergence of Adam and Beyond 

Adam 

AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods

